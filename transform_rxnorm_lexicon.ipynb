{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a rxnorm lexicon of generic and brand drug names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--author -- AR Dirkson\n",
    "\n",
    "--Python v2.7-- \n",
    "\n",
    "In this script, the RxNorm database is used to create a list for spelling correction and to create a drug name normalization lexicon. RxNorm is part of the UMLS and requires you to load only the RxNorm during the MetamorphoSys download.\n",
    "\n",
    "First apply for a license to access the UMLS: https://www.nlm.nih.gov/databases/umls.html\n",
    "\n",
    "Then download the newest version of the UMLS which includes MetamorphoSys\n",
    "https://www.nlm.nih.gov/research/umls/licensedcontent/umlsknowledgesources.html\n",
    "\n",
    "Use MetamorphoSys to load the files (approx 30 min)\n",
    "\n",
    "Use the load scripts which you can request during this loading (explained below) to load UMLS into SQL): \n",
    "https://www.nlm.nih.gov/research/umls/implementation_resources/scripts/index.html\n",
    "\n",
    "Requirements: MySQL version 5.5 and an account on MySQL. Make sure that mySQL has started on your computer (for Windows: check Services to see if the service has started).\n",
    "\n",
    "For the normalization lexicon, only the first chemical names is taken as the key for the dictionary (the word you normalize to) and other chemical names and all brand names are used for the values (the words you want to normalize). Any ambiguous terms, defined as: terms that occur in more than 1 category, are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import MySQLdb\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk import word_tokenize\n",
    "import csv\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connecting to SQL Server RxNorm database\n",
    " \n",
    "Retrieving all strings which are connected to the relation 'has_tradename'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = MySQLdb.connect(host=\"localhost\",\n",
    "                             user=\"root\",\n",
    "                             passwd=\"yourpasswd\",\n",
    "                             db=\"rxnorm\")\n",
    "\n",
    "cursor = db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"SELECT cui1, cui2 FROM mrrel WHERE RELA = 'has_tradename';\"\n",
    "cursor.execute(sql)\n",
    "\n",
    "generic_drugs = []\n",
    "brandnames = []\n",
    "\n",
    "for row in cursor.fetchall():\n",
    "    drug = row[1]\n",
    "    generic_drugs.append(drug)\n",
    "    brand = row[0]\n",
    "    brandnames.append(brand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C2355841', 'C0042845', 'C0546173', 'C0060276', 'C0896320', 'C0075429', 'C1725664', 'C0037732', 'C2242042', 'C2344347']\n",
      "['C0593953', 'C0718535', 'C0718535', 'C0718535', 'C0718535', 'C0718535', 'C0718535', 'C0721372', 'C0721476', 'C0721476']\n",
      "<type 'str'>\n",
      "<type 'str'>\n",
      "  Generic drug ID Brand name ID\n",
      "0        C2355841      C0593953\n",
      "1        C0042845      C0718535\n",
      "2        C0546173      C0718535\n",
      "3        C0060276      C0718535\n",
      "4        C0896320      C0718535\n",
      "5        C0075429      C0718535\n",
      "6        C1725664      C0718535\n",
      "7        C0037732      C0721372\n",
      "8        C2242042      C0721476\n",
      "9        C2344347      C0721476\n",
      "       Generic drug ID Brand name ID\n",
      "106531        C2343065      C2346388\n",
      "106532        C2345617      C2346388\n",
      "106533        C2345653      C2346388\n",
      "106534        C2345994      C2346388\n",
      "106535        C2346386      C2346388\n",
      "106536        C2346387      C1878263\n",
      "106537        C2346394      C1951506\n",
      "106538        C2346396      C1965885\n",
      "106539        C2242042      C0306780\n",
      "106540        C2344347      C0306867\n",
      "106541\n"
     ]
    }
   ],
   "source": [
    "print(generic_drugs [0:10])\n",
    "print(brandnames [0:10])\n",
    "\n",
    "print(type(generic_drugs[0]))\n",
    "print(type(brandnames[0]))\n",
    "\n",
    "g = pd.DataFrame (generic_drugs)\n",
    "b = pd.DataFrame (brandnames)\n",
    "lex = pd.concat ((g,b), axis = 1)\n",
    "\n",
    "lex.columns = [\"Generic drug ID\", \"Brand name ID\"]\n",
    "\n",
    "print (lex.iloc [0:10])\n",
    "\n",
    "print (lex.iloc [-10:])\n",
    "\n",
    "print(len(lex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generic drug ID    0\n",
       "Brand name ID      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if there are Nan values in the lists\n",
    "lex.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the IDs for generic and brand name drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve the primary name \n",
    "\n",
    "generic_drugs_names = []\n",
    "\n",
    "for id in lex [\"Generic drug ID\"]: \n",
    "    #print (id)\n",
    "    query = id \n",
    "    query = repr(query).replace(\"'\", \"\\'\").replace('\"', '\\\"')\n",
    "    sql = \"SELECT STR FROM mrconso WHERE cui = {};\".format(query)\n",
    "    cursor.execute(sql)\n",
    "\n",
    "    generic_drugs_names.append(cursor.fetchone())\n",
    "            \n",
    "len(generic_drugs_names)\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieving alternative generic drug names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alternative_names = [0]*len(lex)\n",
    "\n",
    "for z, id in enumerate (lex[\"Generic drug ID\"]):\n",
    "    query = id \n",
    "    query = repr(query).replace(\"'\", \"\\'\").replace('\"', '\\\"')\n",
    "    sql = \"SELECT STR FROM mrconso WHERE cui = {};\".format(query)\n",
    "    cursor.execute(sql)\n",
    "    \n",
    "    temp_list = []\n",
    "    \n",
    "    for i, row in enumerate (cursor.fetchall ()):\n",
    "        if i == 0: \n",
    "            next\n",
    "        else: \n",
    "            drug = row[0]\n",
    "            temp_list.append (drug)\n",
    "            #if i ==3: \n",
    "                #print (z)\n",
    "    \n",
    "    alternative_names[z] = temp_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(alternative_names[550])\n",
    "\n",
    "print(generic_drugs_names[550])\n",
    "\n",
    "## lengths should be the same\n",
    "\n",
    "print(len(generic_drugs_names))\n",
    "\n",
    "print(len(alternative_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieving brand names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_brandnames = [0]*len(lex)\n",
    "\n",
    "for z, id in enumerate (lex [\"Brand name ID\"]):\n",
    "    query = id \n",
    "    query = repr(query).replace(\"'\", \"\\'\").replace('\"', '\\\"')\n",
    "    sql = \"SELECT STR FROM mrconso WHERE cui = {};\".format(query)\n",
    "    cursor.execute(sql)\n",
    "    \n",
    "    temp_list = []\n",
    "    \n",
    "    for i, row in enumerate (cursor.fetchall ()):\n",
    "        drug = row[0]\n",
    "        temp_list.append (drug)\n",
    "        #if i ==3: \n",
    "           # print (z)\n",
    "    \n",
    "    drug_brandnames[z] = temp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (drug_brandnames[0])\n",
    "print (generic_drugs_names [0])\n",
    "print (drug_brandnames [54])\n",
    "print (generic_drugs_names [54])\n",
    "\n",
    "print(len(drug_brandnames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Making a dictionary out of the seperate lists_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing the keys (the first generic drug name) - removing details of dosage and administration method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## word lists ## \n",
    "\n",
    "list_of_dosages = ['mg/ml', 'mg/mg', 'mci/ml', 'ml', 'mg', 'gm', 'gbq', 'mcg/actuat', 'actuat', 'mci'\n",
    "                   , 'mw', 'sq-hdm', 'meq/ml', 'meq', 'mcg']\n",
    "\n",
    "list_of_extra_words = [' oral', ' solution', ' suspension', ' injection', ' table', ' extract', \n",
    "                       ' whole', ' product', ' release', ' topical', ' ointment',' prefilled', ' syringe', ' chewable',\n",
    "                      ' extended', ' oil', ' spray', ' gel', ' taper', ' medicated', ' patch'\n",
    "                      , ' pack', ' cream', ' dose', ' metered', ' pill', ' shampoo', ' rinse', ' ingredients',\n",
    "                      ' inhaler', ' sublingual', ' capsule', ' soap', ' liquid', ' powder', ' lotion', ' mask', ' masque']\n",
    "\n",
    "#the space at the start of the word ensures that the word is not part of a bigger word but a space after the word would mean \n",
    "#that words at the end of a sentence would not be removed. \n",
    "\n",
    "list_of_time_words = [' per ', ' hour ', ' -hr ', ' hr ' ' -day ', ' day ', ' -week ', ' week ', ' -month ', ' month ']\n",
    "#these words are more likely to be part of bigger words so they need a space after and before them\n",
    "\n",
    "##cleaning functions ##\n",
    "def first_clean (text0): \n",
    "    text1 = re.sub('\\s\\[[a-zA-Z0-9_\\/ -]+\\]', '', text0)  #remove extra information in [] and ()\n",
    "    text2 = re.sub('\\s\\([a-zA-Z0-9_\\/ -]+\\)', '', text1) \n",
    "    text3 = re.sub(r'[\\+\\*#\\!\\?;><\\^@\\|\\.=&%\\(\\)$~_§\\\\:\\…\\\"\\[\\]´`\\,\\'\\'\"\"…¨\\{\\}]+', '', text2) #remove punctuation\n",
    "    return text3\n",
    "\n",
    "def word_split (corpus, corpus2): #corpus is the original, corpus2 is the one you are writing to\n",
    "    for a, i in enumerate (corpus):\n",
    "        temp = i.split (' / ')\n",
    "        for y, z in enumerate (temp): \n",
    "            if y == 0: \n",
    "                corpus2.append (z)\n",
    "            if y > 0: \n",
    "                extra.append (z)\n",
    "                extra_num.append (a)\n",
    "\n",
    "def lex_word_removal (text0, word): #remove unnecessary words\n",
    "    text1 = text0.replace (word, '')\n",
    "    return text1\n",
    "\n",
    "def lex_word_removal_space (text0, word): #remove unnecessary words that need to replaced with a space\n",
    "    text1 = text0.replace (word, ' ')\n",
    "    return text1\n",
    "\n",
    "#remove extra spacing and words likely to occur as start of drug names so need extra space\n",
    "def post_split_clean (text0): \n",
    "    text1 = text0.replace (' in ', ' ') #remove the word in\n",
    "    text2 = text1.replace ('/', '') # remove additional / \n",
    "    text3= re.sub('(([^-]|\\A)[\\d]+([^-]|\\Z))',' ', text2)  #remove digits that are not attached to words with a hyphen\n",
    "    text4= text3.replace ('  ', ' ') #remove double spacing\n",
    "    text5 = re.sub('(\\A\\s|\\s\\Z)', '', text4) #remove spacing at the end or beginning of strings\n",
    "    return text5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generic_drugs_names2 = []\n",
    "\n",
    "for token in generic_drugs_names: \n",
    "    token1 = str(token)\n",
    "    token2 = token1.lower()\n",
    "    generic_drugs_names2.append(token2)                     \n",
    "\n",
    "generic_drugs_names2 = [first_clean(m) for m in generic_drugs_names2]  \n",
    "    \n",
    "generic_drugs_names_spl = []\n",
    "extra = []\n",
    "extra_num = []\n",
    "\n",
    "word_split(generic_drugs_names2, generic_drugs_names_spl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(generic_drugs_names2))\n",
    "print(len(generic_drugs_names_spl))\n",
    "print(len(extra))\n",
    "print(len(extra_num))\n",
    "\n",
    "print (extra[0:10])\n",
    "print(extra_num[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in list_of_dosages: \n",
    "    print (word) \n",
    "    generic_drugs_names_spl = [lex_word_removal (m, word) for m in generic_drugs_names_spl]\n",
    "    extra = [lex_word_removal (m, word) for m in extra]\n",
    "\n",
    "for word in list_of_time_words: \n",
    "    print (word) \n",
    "    generic_drugs_names_spl = [lex_word_removal_space (m, word) for m in generic_drugs_names_spl]\n",
    "    extra = [lex_word_removal (m, word) for m in extra]\n",
    "\n",
    "#make a seperate list of first generic drug names with application method included to use as values\n",
    "generic_drug_names_first_wappl = generic_drugs_names_spl\n",
    "\n",
    "#only remove the type of application in the generic drug names that will function as keys\n",
    "\n",
    "for word in list_of_extra_words: \n",
    "    print (word) \n",
    "    generic_drugs_names_spl = [lex_word_removal (m, word) for m in generic_drugs_names_spl] \n",
    "    \n",
    "#last cleaning function\n",
    "    \n",
    "generic_drugs_names_spl = [post_split_clean(m) for m in generic_drugs_names_spl]\n",
    "generic_drug_names_first_wappl = [post_split_clean(m) for m in generic_drug_names_first_wappl]\n",
    "extra = [post_split_clean(m) for m in extra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(extra))\n",
    "print(len(extra_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing the alternative drug names and brand names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate the alternative and brand names\n",
    "\n",
    "alt_names_total = [0]*len(alternative_names)\n",
    "\n",
    "for i in range (len(alternative_names)): \n",
    "    alt_names_total [i] = alternative_names[i] + drug_brandnames [i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(alternative_names[54])\n",
    "print(drug_brandnames [54])\n",
    "print(alt_names_total [54])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lower the words \n",
    "alt_names_total2 = []\n",
    "\n",
    "for row in alt_names_total:\n",
    "    for a, word in enumerate (row):\n",
    "        word1 = word.lower ()\n",
    "        row[a] = word1\n",
    "    alt_names_total2.append(row)\n",
    "\n",
    "z= alt_names_total2[0]\n",
    "print(z)\n",
    "print(type(z))\n",
    "print(z[0])\n",
    "print(type(z[0]))\n",
    "            \n",
    "print(len(alt_names_total))\n",
    "print(len(alt_names_total2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first preprocessing step: first_clean\n",
    "alt_names_total3 = []\n",
    "\n",
    "for row in alt_names_total2: \n",
    "    row2 = [first_clean(m) for m in row] \n",
    "    alt_names_total3.append(row2)\n",
    "            \n",
    "print(len(alt_names_total3))\n",
    "print(len(alt_names_total2))\n",
    "\n",
    "z= alt_names_total3[54]\n",
    "print(z)\n",
    "print(type(z))\n",
    "print(z[0])\n",
    "print(type(z[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the words with / between them\n",
    "alt_names_total_spl = []\n",
    "\n",
    "def word_split_alt (corpus, corpus2): #corpus is the original, corpus2 is the one you are writing to\n",
    "    for a, row in enumerate (corpus):\n",
    "        temp2 = []\n",
    "        for b, word in enumerate(row):\n",
    "            temp = word.split (' / ')\n",
    "            temp2.append(temp)\n",
    "        flat_temp2 = [item for sublist in temp2 for item in sublist]\n",
    "        corpus2.append(flat_temp2)\n",
    "\n",
    "word_split_alt(alt_names_total3, alt_names_total_spl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(alt_names_total2))\n",
    "print(len(alt_names_total3))\n",
    "print(len(alt_names_total_spl))\n",
    "\n",
    "z= alt_names_total_spl[54]\n",
    "print(z)\n",
    "print(type(z))\n",
    "print(z[0])\n",
    "print(type(z[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This appends the other generic names split from the first generic name (stored in extra) \n",
    "# to the list of alternative names that already exist.\n",
    "print(alt_names_total_spl[38])\n",
    "\n",
    "for a, i in enumerate (extra):\n",
    "    y = extra_num[a]\n",
    "    alt_names_total_spl[y].append (i)\n",
    "    \n",
    "#This appends the version of the first generic names with application method included to the list of values\n",
    "\n",
    "for a, i in enumerate (generic_drug_names_first_wappl):\n",
    "    alt_names_total_spl[a].append (i)\n",
    "    \n",
    "print(alt_names_total_spl[38]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z= alt_names_total_spl[38]\n",
    "print(z)\n",
    "print(type(z))\n",
    "print(z[0])\n",
    "print(type(z[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing after the splitting of words with post_split_clean function \n",
    "\n",
    "alt_names_total_spl2 = alt_names_total_spl\n",
    "\n",
    "for word in list_of_dosages: \n",
    "    print (word) \n",
    "    for a,i in enumerate (alt_names_total_spl2): \n",
    "        i = [lex_word_removal (m, word) for m in i]\n",
    "        alt_names_total_spl2[a] = i\n",
    "        \n",
    "for a, i in enumerate(alt_names_total_spl2): \n",
    "    i = [post_split_clean(m) for m in i]\n",
    "    alt_names_total_spl2[a] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(alt_names_total_spl2 [54])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get rid of duplicates in generic drug names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_dict_gen_nodup = []\n",
    "kept_list = []\n",
    "removed_list = []\n",
    "removed_list_due_to = []\n",
    "\n",
    "def remove_dupl_special(corp, new_corp): #to enable syncing need to enumerate what is kept \n",
    "    for a, i in enumerate (corp): \n",
    "        if i in new_corp: \n",
    "            removed_list.append (a)\n",
    "            for c, z in enumerate (corp): \n",
    "                if i == z: \n",
    "                    removed_list_due_to.append (c) \n",
    "                    break\n",
    "        if i not in new_corp: \n",
    "            new_corp.append(i)    \n",
    "            kept_list.append (a)\n",
    "\n",
    "remove_dupl_special (generic_drugs_names_spl, norm_dict_gen_nodup)\n",
    "\n",
    "print(len(generic_drugs_names_spl))\n",
    "print(len(norm_dict_gen_nodup))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_dict_gen2 = generic_drugs_names_spl\n",
    "\n",
    "print(norm_dict_gen2[11])\n",
    "print(norm_dict_gen2[14])\n",
    "print(norm_dict_gen2[13])\n",
    "print(norm_dict_gen2[50])\n",
    "print(norm_dict_gen2[121])\n",
    "\n",
    "##yeeey it seems to work "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the medication names for the same generic drugs using 'removed list' - this is a list of all the chemical names that were not included as keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(alt_names_total_spl [38])\n",
    "\n",
    "print(type(alt_names_total_spl))\n",
    "\n",
    "print(type(alt_names_total_spl[0]))\n",
    "\n",
    "for i in alt_names_total_spl2[-100]: \n",
    "    print (i)\n",
    "    print(type(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_dict_alt = alt_names_total_spl2\n",
    "\n",
    "for i in range (len(removed_list)):\n",
    "    temp = []\n",
    "    for z in norm_dict_alt[removed_list[i]]: \n",
    "        temp.append (z)\n",
    "    for z in norm_dict_alt [removed_list_due_to[i]]: \n",
    "        temp.append (z)\n",
    "    norm_dict_alt [removed_list_due_to[i]] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(alt_names_total_spl2[13]))\n",
    "print(len(norm_dict_alt[13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we can remove the alternative names attached to the removed generic names \n",
    "norm_dict_alt2 = []\n",
    "\n",
    "for i in range (len(kept_list)): \n",
    "     norm_dict_alt2.append(norm_dict_alt[kept_list[i]])\n",
    "    \n",
    "print(len(norm_dict_alt2))\n",
    "print(len(norm_dict_gen_nodup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z= norm_dict_alt2[38]\n",
    "print(z)\n",
    "print(type(z))\n",
    "print(z[0])\n",
    "print(type(z[0]))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the duplicates within the lists "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ['boat', 'blue', 'moon', 'blue'], ['bag', 'red', 'bag', 'yellow']\n",
    "test2 = []\n",
    "\n",
    "for a in range(len(test)): \n",
    "    temp = []\n",
    "    for i in test[a]: \n",
    "        if i not in temp:\n",
    "            temp.append(i)\n",
    "    test2.append(temp)\n",
    "    \n",
    "print(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_dict_alt3 = []\n",
    "\n",
    "for a in norm_dict_alt2: \n",
    "    temp = []\n",
    "    for i in a: \n",
    "        if i not in temp:\n",
    "            temp.append(i)\n",
    "    norm_dict_alt3.append(temp)\n",
    "    \n",
    "# def remove_dupl(corp, new_corp): \n",
    "#     for i in corp: \n",
    "#         if i not in new_corp: \n",
    "#             new_corp.append(i)\n",
    "\n",
    "print (len(norm_dict_alt3))\n",
    "# print(norm_dict_alt3[13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z= norm_dict_alt3[38]\n",
    "print(z)\n",
    "print(type(z))\n",
    "print(z[0])\n",
    "print(type(z[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_dict_alt_df  = pd.DataFrame (norm_dict_alt3)\n",
    "norm_dict_alt_df.to_csv ('C:\\\\Users\\\\dirksonar\\\\Documents\\\\Data\\\\umls_extraction\\\\data\\\\norm_dict_alt_nodup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_dict_gen_nodup[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove all from alternative names that are also in generic names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lex_word_removal (text0, word): #remove extra spacing and superfluous words\n",
    "    text1 = text0.replace (word, '')\n",
    "    return text1\n",
    "\n",
    "norm_dict_alt4 = norm_dict_alt3\n",
    "\n",
    "for word in norm_dict_gen_nodup: \n",
    "    for a, i in enumerate(norm_dict_alt3): \n",
    "        temp = []\n",
    "        for token in i: \n",
    "            if token != word: \n",
    "                temp.append(token)\n",
    "        norm_dict_alt4[a] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z= norm_dict_alt4[38]\n",
    "print(z)\n",
    "print(type(z))\n",
    "print(z[0])\n",
    "print(type(z[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for duplicates between the lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counter on all words in a flat list and if any are more than 1 it is bad\n",
    "\n",
    "norm_dict_alt4_flat = [word for sublist in norm_dict_alt4 for word in sublist]\n",
    "\n",
    "from collections import Counter \n",
    "\n",
    "count = Counter(norm_dict_alt4_flat)\n",
    "\n",
    "print(count.most_common(100))\n",
    "\n",
    "# for i in list(count.values()): \n",
    "#     if i > 1: \n",
    "#         print (\"Duplicate!\")\n",
    "#         print (i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove any ambiguous terms (so terms that are duplicates across different lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_duplicate_keys =[]\n",
    "\n",
    "z = list(count.keys())\n",
    "\n",
    "for a, i in enumerate (list(count.values())): \n",
    "    if i > 1: \n",
    "        list_of_duplicate_keys.append(z[a])\n",
    "        \n",
    "#print(list_of_duplicate_keys)\n",
    "\n",
    "x = len(list_of_duplicate_keys)\n",
    "print(x)\n",
    "\n",
    "y = len(count.keys())\n",
    "print(y)\n",
    "\n",
    "perc = (float(x)/float (y)*100)\n",
    "print(perc)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in list_of_duplicate_keys: \n",
    "    for a, i in enumerate(norm_dict_alt4): \n",
    "        temp = []\n",
    "        for token in i: \n",
    "            if token != word: \n",
    "                temp.append(token)\n",
    "        norm_dict_alt4[a] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obj(obj, name):\n",
    "     with open(name + '.pkl', 'wb') as f:\n",
    "         pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(list_of_duplicate_keys[0:10])\n",
    "save_obj(list_of_duplicate_keys, 'list_of_removed_ambiguous_terms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(norm_dict_alt4)\n",
    "\n",
    "z= norm_dict_alt4[38]\n",
    "print(z)\n",
    "print(type(z))\n",
    "print(z[0])\n",
    "print(type(z[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re-check if duplicates are gone \n",
    "\n",
    "norm_dict_alt4_flat2 = [word for sublist in norm_dict_alt4 for word in sublist]\n",
    "\n",
    "from collections import Counter \n",
    "\n",
    "count2 = Counter(norm_dict_alt4_flat2)\n",
    "\n",
    "#print(count2.most_common(100))\n",
    "\n",
    "for i in list(count2.values()): \n",
    "    if i > 1: \n",
    "        print (\"Duplicate!\")\n",
    "        print (i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get rid of repeats in phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize \n",
    "\n",
    "norm_dict_alt5 = norm_dict_alt4\n",
    "\n",
    "for a, li in enumerate (norm_dict_alt5): \n",
    "    li2 = []\n",
    "    for phrase in li:\n",
    "        phrase = word_tokenize (str(phrase))\n",
    "        temp = []\n",
    "        for word in phrase:\n",
    "            if word not in temp: \n",
    "                temp.append (word)\n",
    "        phrase = \" \".join(temp)\n",
    "        li2.append(phrase)\n",
    "    norm_dict_alt5[a] = li2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(norm_dict_alt4))\n",
    "print(len(norm_dict_alt5))\n",
    "\n",
    "z= norm_dict_alt5[38]\n",
    "print(z)\n",
    "print(type(z))\n",
    "print(z[0])\n",
    "print(type(z[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_norm_dict = {}\n",
    "\n",
    "for i in range (len(norm_dict_gen_nodup)): \n",
    "    drug_norm_dict[norm_dict_gen_nodup[i]] = norm_dict_alt4[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(drug_norm_dict['imatinib'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_norm_dict_no_rep = {}\n",
    "\n",
    "for i in range (len(norm_dict_gen_nodup)): \n",
    "    drug_norm_dict_no_rep[norm_dict_gen_nodup[i]] = norm_dict_alt5[i]\n",
    "    \n",
    "print(drug_norm_dict_no_rep['imatinib'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj(drug_norm_dict, 'drug_normalize_dict')\n",
    "save_obj(drug_norm_dict_no_rep, 'drug_normalize_dict_no_repeats')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
